{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#FlipFeed"
      ],
      "metadata": {
        "id": "cKmHf_etYoop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Objetivo:\n",
        "> Identificar cuando una persona realiza una dominada correctamente\n",
        "\n",
        "###Metodo:\n",
        "> Usaremos en este caso, redes neuronales recurrentes para obtener un valor booleano\n",
        "\n",
        "###Herramientas:\n",
        "\n",
        "0.   Python\n",
        "1.   Keras - TensorFLow\n",
        "2.   Yolo v8 - entrenado con un data set personalizado\n",
        "3.   OpenCV optical flow\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BlKdGeWYYvW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Yolo v8 y OpenCV Optical Flow\n",
        "Yolov8 lo utilizamos para etiquetar los objetos en el video, podiendo así extraer las coordenadas en donde se encuentra la persona y el balón.\n",
        "Acontinuación instalamos todos los paquetes necesarios."
      ],
      "metadata": {
        "id": "Y2rxHWTub5x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy opencv-python ultralytics supervision==0.1.0 "
      ],
      "metadata": {
        "id": "ny_QV-_ldE_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necesary libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import time\n",
        "from ultralytics import YOLO\n",
        "\n",
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.tools.detections import Detections, BoxAnnotator"
      ],
      "metadata": {
        "id": "YtLs4oEEd0dK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "cwd = os.getcwd()\n",
        "files = os.listdir(cwd)\n",
        "print(\"Files in %r: %s\" % (cwd, files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCwjkHnnlPte",
        "outputId": "19b00aee-67ae-4569-aa84-29649d9f5b93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in '/content': ['.config', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##OpenCV Optical Flow"
      ],
      "metadata": {
        "id": "_3alb5EWiNgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CoN8nkBzmMZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To draw the lines on the frame\n",
        "def draw_flow(img, flow, step=20):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n",
        "    fx, fy = flow[y,x].T\n",
        "\n",
        "    lines = np.vstack([x, y, x-fx, y-fy]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines + 0.5)\n",
        "\n",
        "    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.polylines(img_bgr, lines, 0, (0, 255, 0))\n",
        "\n",
        "    for (x1, y1), (_x2, _y2) in lines:\n",
        "        cv2.circle(img_bgr, (x1, y1), 1, (0, 255, 0), -1)\n",
        "\n",
        "    return img_bgr\n",
        "\n",
        "#Capture the video and generate a output with cv2\n",
        "videoPath = 'dom2.mp4'\n",
        "input = cv2.VideoCapture(videoPath)\n",
        "output = cv2.VideoWriter('./Output/output_' + videoPath, cv2.VideoWriter_fourcc(*'mp4v'), 50, (int(input.get(3)),int(input.get(4))))\n",
        "\n",
        "suc, prev = input.read()\n",
        "prevgray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "while True:\n",
        "\n",
        "    #Extract a frame from video and put on it a B&W format \n",
        "    suc, img = input.read()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    #Obtain the motion prediction\n",
        "    flow = cv2.calcOpticalFlowFarneback(prevgray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    prevgray = gray\n",
        "\n",
        "    #Show the frame and write frames on output\n",
        "    imgToShow = draw_flow(gray, flow)\n",
        "    cv2.imshow('flow', imgToShow)\n",
        "    output.write(imgToShow)\n",
        "\n",
        "    key = cv2.waitKey(5)\n",
        "    if key == ord('q'):\n",
        "        break\n",
        "\n",
        "output.release()\n",
        "input.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "gBI7KN8xiMYk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}